{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from torch import nn;\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "\n",
    "DATA_DIR = './data/'\n",
    "DOCS_DIR = './docs/'\n",
    "MIN_WORD_FREQUENCY = 100\n",
    "FORCE_RETRAIN = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = get_tokenizer('basic_english')\n",
    "\n",
    "def read_lines(\n",
    "    dataset: str\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Reads all the lines form all the texts in the given `dataset`.\n",
    "\n",
    "    Datasets are `train`, `val` and `test`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scan for all input files\n",
    "    inDirectoryName = os.path.join(DATA_DIR, 'input', dataset)\n",
    "    inFileNames = [os.path.join(inDirectoryName, f) for f in os.listdir(inDirectoryName)]\n",
    "\n",
    "    # Read all the lines from all the files\n",
    "    lines = []\n",
    "    for inFileName in inFileNames:\n",
    "        with open(inFileName, 'r') as file:\n",
    "            lines += file.readlines()\n",
    "\n",
    "    print(f\"Read {len(lines)} lines from {dataset}\")\n",
    "    return lines\n",
    "\n",
    "def create_tokens(\n",
    "    dataset: str\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Creates tokens for all the words in the given `dataset`.\n",
    "\n",
    "    Datasets are `train`, `val` and `test`.\n",
    "    \"\"\"\n",
    "\n",
    "    outFileName = os.path.join(DATA_DIR, f'words.{dataset}.pt')\n",
    "    \n",
    "    # If the file exists, don't create it again.\n",
    "    if os.path.isfile(outFileName):\n",
    "        print(f\"Loaded tokenized words for {dataset} ({outFileName})\")\n",
    "        return torch.load(outFileName)\n",
    "\n",
    "    tokens = []\n",
    "    for line in read_lines(dataset):\n",
    "        tokens += TOKENIZER(line)\n",
    "\n",
    "    # Save tokens so we dont have to do this again\n",
    "    torch.save(tokens, outFileName)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def create_vocabulary(\n",
    "    dataset: str\n",
    ") -> Vocab:\n",
    "    \"\"\"\n",
    "    Creates a vocabulary for the given `dataset`.\n",
    "\n",
    "    Datasets are `train`, `val` and `test`.\n",
    "    \"\"\"\n",
    "\n",
    "    outFileName = os.path.join(DATA_DIR, f'vocabulary.pt')\n",
    "\n",
    "    # If the file exists, don't create it again.\n",
    "    if os.path.isfile(outFileName):\n",
    "        print(f\"Loaded vocabulary for {dataset} ({outFileName})\")\n",
    "        return torch.load(outFileName)\n",
    "\n",
    "    def read_sanitize_tokenize():\n",
    "\n",
    "        for line in read_lines(dataset):\n",
    "\n",
    "            line = re.sub('\\\\w*[0-9]+\\\\w*', ' ', line) # Remove numbers\n",
    "            line = re.sub('\\\\w*[A-Z]+\\\\w*', ' ', line) # Remove uppercase names\n",
    "            line = re.sub('\\\\s+', ' ', line) # Remove double spaces\n",
    "\n",
    "            yield TOKENIZER(line)\n",
    "\n",
    "    vocabulary = build_vocab_from_iterator(read_sanitize_tokenize(), min_freq=MIN_WORD_FREQUENCY, specials=['<unk>'])\n",
    "\n",
    "    vocabulary.set_default_index(vocabulary['<unk>'])\n",
    "\n",
    "    # We removed all uppercase names, this includes 'I'\n",
    "    vocabulary.append_token('i') \n",
    "\n",
    "    # Save vocabulary so we dont have to do this again\n",
    "    torch.save(vocabulary, outFileName)\n",
    "\n",
    "    return vocabulary\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenized words for train (./data/words.train.pt)\n",
      "Loaded tokenized words for val (./data/words.val.pt)\n",
      "Loaded tokenized words for test (./data/words.test.pt)\n",
      "Loaded vocabulary for train (./data/vocabulary.pt)\n"
     ]
    }
   ],
   "source": [
    "words_train = create_tokens('train')\n",
    "words_val = create_tokens('val')\n",
    "words_test = create_tokens('test')\n",
    "\n",
    "vocabulary = create_vocabulary('train')\n",
    "VOCABULARY_SIZE = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in 'train' dataset ........: 2684706\n",
      "Words in 'val' dataset ..........: 49526\n",
      "Words in 'test' dataset .........: 124152\n",
      "Distinct words in 'train' dataset: 52105\n",
      "Words in vocabulary .............: 1880\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def print_dataset_info():\n",
    "    print(\"Words in 'train' dataset ........:\", len(words_train))\n",
    "    print(\"Words in 'val' dataset ..........:\", len(words_val))\n",
    "    print(\"Words in 'test' dataset .........:\", len(words_test))\n",
    "    print(\"Distinct words in 'train' dataset:\", len(set(words_train)))\n",
    "    print(\"Words in vocabulary .............:\", VOCABULARY_SIZE)\n",
    "\n",
    "    bars = plt.bar(['Train', 'Validation', 'Test', 'Unique', 'Vocabulary'], [len(words_train), len(words_val), len(words_test), len(set(words_train)), VOCABULARY_SIZE])\n",
    "    plt.title('Word counts')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel('Word count')\n",
    "    plt.gca().yaxis.set_visible(False)\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05, yval, ha='center', va='bottom')\n",
    "    plt.savefig(DOCS_DIR + 'word_counts.png')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "print_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "This section contains som utilites which come in handy for all the next assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nameof(\n",
    "    model: nn.Module, \n",
    "    criterion: object, \n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Creates a good name for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    name = f'{model.__class__.__name__}_{criterion.__class__.__name__}_{optimizer.__class__.__name__}'\n",
    "    options = optimizer.param_groups[0]\n",
    "\n",
    "    if 'lr' in options:\n",
    "        name += f'-lr{options[\"lr\"]:.4f}'\n",
    "\n",
    "    if 'momentum' in options and options['momentum'] != 0.0:\n",
    "        name += f'-m{options[\"momentum\"]:.4f}'\n",
    "\n",
    "    if 'weight_decay' in options and options['weight_decay'] != 0.0:\n",
    "        name += f'-wd{options[\"weight_decay\"]:.4f}'\n",
    "\n",
    "    return name\n",
    "\n",
    "def model_save(model: nn.Module, folder: str | None = None):\n",
    "    \"\"\"\n",
    "    Save the given model to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    folder = '' if folder is None else folder + '/'\n",
    "    filename = DATA_DIR + f'{folder}{model.name}.pt'\n",
    "\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f'Saved {model.name} ({filename})')\n",
    "\n",
    "def model_load(model: nn.Module, folder: str | None = None) -> bool:\n",
    "    \"\"\"\n",
    "    Save the given model to a file.\n",
    "\n",
    "    Returns `True` if the model was loaded, `False` otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if FORCE_RETRAIN:\n",
    "        return False\n",
    "\n",
    "    folder = '' if folder is None else folder + '/'\n",
    "    filename = DATA_DIR + f'{folder}{model.name}.pt'\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        return False\n",
    "    \n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    print(f'Loaded {model.name} ({filename}')\n",
    "    return True\n",
    "\n",
    "def dataset_create(\n",
    "    words: list[str],\n",
    "    context_size_before: int = 0,\n",
    "    context_size_after: int = 0,\n",
    "    vocabulary_index_to_target: dict[int, int] | None = None,\n",
    "    dataset_name: str | None = None\n",
    ") -> TensorDataset:\n",
    "    \"\"\"\n",
    "    Creates a dataset from the given words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert in case they are floats\n",
    "    context_size_before = int(context_size_before)\n",
    "    context_size_after = int(context_size_after)\n",
    "\n",
    "    filename = DATA_DIR + f'dataset/{dataset_name}.pt'\n",
    "    if os.path.exists(filename) and dataset_name is not None and not FORCE_RETRAIN:\n",
    "        return torch.load(filename)\n",
    "\n",
    "    word_idx = [vocabulary[word] for word in words]\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for i in range(context_size_before, len(words) - context_size_after):\n",
    "\n",
    "        context_before = word_idx[i-context_size_before:i]\n",
    "        context_after = word_idx[i+1:i+1+context_size_after]\n",
    "        context = context_before + context_after\n",
    "        target = word_idx[i]\n",
    "\n",
    "        if vocabulary_index_to_target is not None:\n",
    "            target = vocabulary_index_to_target.get(target, None)\n",
    "\n",
    "        if target is not None:\n",
    "            contexts.append(torch.tensor(context))\n",
    "            targets.append(target)\n",
    "\n",
    "    contexts = torch.stack(contexts).to(device)\n",
    "    targets = torch.tensor(targets).to(device)\n",
    "\n",
    "    dataset = TensorDataset(contexts, targets)\n",
    "    torch.save(dataset, filename)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def model_train(\n",
    "    model: nn.Module,\n",
    "    dataset: TensorDataset,\n",
    "    criterion: typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "    tranform_targets: typing.Callable[[torch.Tensor], torch.Tensor] = lambda x: x,\n",
    "    tranform_contexts: typing.Callable[[torch.Tensor], torch.Tensor] = lambda x: x,\n",
    "    model_category: str = \"models\",\n",
    "    retrain: bool = False,\n",
    "    figure_tag: str = \"\"\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Trains the given `model` with the given `dataset`.  \n",
    "\n",
    "    dataset: The dataset to train the model with.\n",
    "    model: The model to train.\n",
    "    criterion: The loss function to use.\n",
    "    optimizer: The optimizer to use.\n",
    "    batch_size: The batch size to use.\n",
    "    epochs: The number of epochs to train.\n",
    "    force_retrain: If `True`, the model will be trained even if it has been trained before.\n",
    "    tranform_targets: A function to transform the targets before they are passed to `criterion` along with the `model` output.\n",
    "    tranform_contexts: A function to transform the contexts before they are passed to `model`.\n",
    "    model_category: The category of the model. If `None`, the model's class name will be used.\n",
    "    \"\"\"\n",
    "    criterion.to(device)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Name the model for easier referencing\n",
    "    model.name = model_nameof(model, criterion, optimizer)\n",
    "\n",
    "    # If the model has already been trained,\n",
    "    # and we are not forcing a retrain:\n",
    "    #     Load the trained model and return\n",
    "    if (not retrain) and model_load(model, model_category):\n",
    "        return []\n",
    "    \n",
    "    # Prepare a data loader for the given dataset.\n",
    "    # Ensure the data is shuffled.\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print(f'Training {model.name}...')\n",
    "\n",
    "    losses = []\n",
    "    dataset_size = dataset.tensors[0].size(0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = torch.tensor([0.0])\n",
    "\n",
    "        for contexts, targets in data_loader:\n",
    "\n",
    "            # Perform transformations\n",
    "            contexts = tranform_contexts(contexts)\n",
    "            targets = tranform_targets(targets)\n",
    "\n",
    "            # Perform a training step\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(contexts)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.cpu().detach()\n",
    "\n",
    "        loss_sum = loss_sum.item() / dataset_size\n",
    "        losses.append(loss_sum)\n",
    "        print(f'Training | {model.name} | Epoch {epoch} | Loss {loss_sum}')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(losses)\n",
    "    plt.title(f'{model.name} | Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(DOCS_DIR + f'loss_{model.name}{figure_tag}.png')\n",
    "\n",
    "    # Save the model so we can skip training every time.\n",
    "    model_save(model, model_category)\n",
    "\n",
    "    return losses\n",
    "\n",
    "def model_accuracy(\n",
    "    model: nn.Module,\n",
    "    dataset: TensorDataset,\n",
    "    dataset_name: str = 'Validation',\n",
    "    transform_contexts: typing.Callable[[torch.Tensor], torch.Tensor] = lambda x: x,\n",
    "    transform_outputs: typing.Callable[[torch.Tensor], torch.Tensor] = lambda x: x\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the given model on the given dataset.\n",
    "\n",
    "    Returns the accuracy of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    data_loader = DataLoader(dataset, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for contexts, targets in data_loader:\n",
    "        contexts = transform_contexts(contexts).to(device)\n",
    "        outputs = model(contexts)\n",
    "        outputs = transform_outputs(outputs)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += (outputs == targets).sum().item()\n",
    "\n",
    "    print(f'{dataset_name} | {model.name} | Accuracy {correct/total:.4f}')\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def model_pick_best(\n",
    "    models: list[nn.Module],\n",
    "    dataset: TensorDataset,\n",
    "    performance_measure: typing.Callable[[nn.Module, TensorDataset], float],\n",
    "    figure_tag: str = \"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Pick the best model from the given list of `models` on a given `dataset`.\n",
    "    \"\"\"\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    accuracies: dict[str, float] = {}\n",
    "\n",
    "    for model in models:\n",
    "        accuracy = performance_measure(model, dataset)\n",
    "        accuracies[model.name] = accuracy\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "\n",
    "    print(f'Best model: {best_model.name} | Accuracy {best_accuracy:.4f}')\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values()) + list(mcolors.BASE_COLORS.values()) + list(mcolors.CSS4_COLORS.values())\n",
    "    bars = plt.bar(accuracies.keys(), accuracies.values(), color=colors[:len(accuracies)])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.gca().xaxis.set_visible(False)\n",
    "    plt.legend(bars, accuracies.keys())\n",
    "    plt.gca().yaxis.set_visible(False)\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "    plt.savefig(DOCS_DIR + f'accuracy{figure_tag}.png')\n",
    "\n",
    "    return best_model, best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "This section contains the training and selecting of the best performing embeddings using `CBOW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_DIM = 32\n",
    "EMBEDDINGS_CONTEXT_SIZE = 5\n",
    "EMBEDDINGS_BATCH_SIZE = 128\n",
    "EMBEDDINGS_EPOCHS = 100\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(VOCABULARY_SIZE, EMBEDDINGS_DIM, sparse=True)\n",
    "        self.linear = nn.Linear(EMBEDDINGS_DIM*EMBEDDINGS_CONTEXT_SIZE, VOCABULARY_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "def cbow_create_dataset(\n",
    "    words: list[str],\n",
    "    dataset_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a dataset from the given words.\n",
    "    \"\"\"\n",
    "    return dataset_create(words, EMBEDDINGS_CONTEXT_SIZE, dataset_name='cbow.' + dataset_name)\n",
    "\n",
    "def cbow_train(\n",
    "    dataset: TensorDataset,\n",
    "    model: CBOW,\n",
    "    criterion: object,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "):\n",
    "    return model_train(\n",
    "        model, dataset, criterion, optimizer, \n",
    "        model_category='embeddings',\n",
    "        epochs=EMBEDDINGS_EPOCHS, batch_size=EMBEDDINGS_BATCH_SIZE,\n",
    "        tranform_targets=lambda x: torch.nn.functional.one_hot(x, num_classes=VOCABULARY_SIZE).float()\n",
    "    )\n",
    "\n",
    "def cbow_performance(\n",
    "    model: CBOW,\n",
    "    dataset: TensorDataset,\n",
    "    dataset_name: str = 'Validation'\n",
    "):\n",
    "    return model_accuracy(\n",
    "        model, dataset, dataset_name,\n",
    "        transform_outputs=lambda x: torch.argmax(x, dim=1)\n",
    "    )\n",
    "\n",
    "def cbow_create_embeddings() -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create multiple embeddings models and pick the best one.  \n",
    "\n",
    "    Returns the embeddings of the best model.\n",
    "    \"\"\"\n",
    "    training_data = cbow_create_dataset(words_train, 'train')\n",
    "\n",
    "    m1 = CBOW()\n",
    "    cbow_train(\n",
    "        training_data, m1,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        torch.optim.SGD(m1.parameters(), lr=0.02)\n",
    "    )\n",
    "\n",
    "    m2 = CBOW()\n",
    "    cbow_train(\n",
    "        training_data, m2,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        torch.optim.SGD(m2.parameters(), lr=0.01)\n",
    "    )\n",
    "    \n",
    "    m3 = CBOW()\n",
    "    cbow_train(\n",
    "        training_data, m3,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        torch.optim.SGD(m3.parameters(), lr=0.001)\n",
    "    )\n",
    "    \n",
    "    m4 = CBOW()\n",
    "    cbow_train(\n",
    "        training_data, m4,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        torch.optim.Adam(m4.parameters(), lr=0.02)\n",
    "    )\n",
    "    \n",
    "    m5 = CBOW()\n",
    "    cbow_train(\n",
    "        training_data, m5,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        torch.optim.Adam(m5.parameters(), lr=0.002)\n",
    "    )\n",
    "\n",
    "    validation_data = cbow_create_dataset(words_val, 'val')\n",
    "    best_model, best_model_accuracy = model_pick_best(\n",
    "        [m1, m2, m3, m4, m5],\n",
    "        dataset = validation_data,\n",
    "        performance_measure=cbow_performance,\n",
    "        figure_tag='cbow'\n",
    "    )\n",
    "\n",
    "    return best_model.embeddings.weight.detach().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = cbow_create_embeddings()\n",
    "embeddings = torch.load(DATA_DIR + 'embeddings.pt').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insepecting the embeddings\n",
    "In this section we try to understand the embeddings we created in the previous section.  \n",
    "We will identify which words the model believes are similar and take a look at the embeddings using the `Tensorflow Projector` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector_similarity_cosine(word_a:torch.Tensor, word_b:torch.Tensor):\n",
    "    return torch.dot(word_a, word_b) / (word_a.norm() * word_b.norm())\n",
    "\n",
    "def word_vector_similarity_euclidian(word_a:torch.Tensor, word_b:torch.Tensor):\n",
    "    return (word_a - word_b).norm()\n",
    "\n",
    "def word_similarity_cosine(word_a:str, word_b:str):\n",
    "    word_a_idx = vocabulary[word_a]\n",
    "    word_b_idx = vocabulary[word_b]\n",
    "\n",
    "    word_a_embedding = embeddings[word_a_idx]\n",
    "    word_b_embedding = embeddings[word_b_idx]\n",
    "\n",
    "    return word_vector_similarity_cosine(word_a_embedding, word_b_embedding)\n",
    "\n",
    "def word_find_top_closest(\n",
    "    word: str,\n",
    "    top: int\n",
    "):\n",
    "    similarities = []\n",
    "    for other in vocabulary.lookup_tokens(range(len(vocabulary))):\n",
    "        similarity = word_similarity_cosine(word, other).item()\n",
    "        similarities.append((other, similarity))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    similarities = similarities[1:top+1]\n",
    "\n",
    "    return similarities\n",
    "\n",
    "def word_find_closest(\n",
    "    word_vector:torch.Tensor,\n",
    "):\n",
    "    closest_word = None\n",
    "    closest_distance = 1_000_000\n",
    "\n",
    "    for other in vocabulary.lookup_tokens(range(len(vocabulary))):\n",
    "        other_idx = vocabulary[other]\n",
    "        other_embedding = embeddings[other_idx]\n",
    "\n",
    "        distance = word_vector_similarity_euclidian(word_vector, other_embedding)\n",
    "\n",
    "        if distance < closest_distance:\n",
    "            closest_distance = distance\n",
    "            closest_word = other\n",
    "    \n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_words(words, top = 10):\n",
    "    print(f\"Top {top} most similar words\")\n",
    "    for word in words:\n",
    "        if vocabulary[word] == vocabulary['<unk>']:\n",
    "            print(word, ':', \"Not in vocabulary\")\n",
    "        else:\n",
    "            print(word, ':', [x[0] for x in word_find_top_closest(word, top)])\n",
    "\n",
    "print_most_similar_words([\n",
    "    'king', 'queen', 'man', 'woman', 'he', 'she', 'doctor', 'nurse',\n",
    "    'black', 'white', 'slave', 'master',\n",
    "    'poor', 'rich', \n",
    "    'smart', 'dumb', \n",
    "    'strong', 'weak',\n",
    "    'good', 'bad',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_projector_create_data():\n",
    "    e = embeddings.cpu().numpy()\n",
    "    e = pd.DataFrame(e)\n",
    "    e.to_csv(DATA_DIR + 'tensorflow_projector/embeddings.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "    v = vocabulary.lookup_tokens(range(len(vocabulary)))\n",
    "    v = pd.DataFrame(v)\n",
    "    v.to_csv(DATA_DIR + 'tensorflow_projector/vocabulary.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "tensorflow_projector_create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugating _be_ and _have_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHAVE_CONTEXT_SIZE = 20\n",
    "BEHAVE_BATCH_SIZE = 8192\n",
    "BEHAVE_EPOCHS = 5\n",
    "BEHAVE_WORDS = ['<unk>', 'be', 'am', 'are', 'is', 'was', 'were', 'been', 'being', 'have', 'has', 'had', 'having']\n",
    "BEHAVE_WORDS_SIZE = len(BEHAVE_WORDS)\n",
    "\n",
    "class BeHaveRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BeHaveRNN, self).__init__()\n",
    "\n",
    "        # self.rnn = nn.RNN(EMBEDDINGS_DIM*BEHAVE_CONTEXT_SIZE, EMBEDDINGS_DIM, batch_first=True).to(device)\n",
    "        self.rnn = nn.RNN(EMBEDDINGS_DIM, EMBEDDINGS_DIM, batch_first=True).to(device)\n",
    "        self.fc1 = nn.Linear(EMBEDDINGS_DIM, BEHAVE_WORDS_SIZE * 4).to(device)\n",
    "        self.fc2 = nn.Linear(BEHAVE_WORDS_SIZE * 4, BEHAVE_WORDS_SIZE).to(device)\n",
    "        self.hidden = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = embeddings[x]\n",
    "\n",
    "        # Reset the state if its incompatible with current input\n",
    "        if self.hidden is not None and self.hidden.size(1) != x.size(0):\n",
    "            self.reset()\n",
    "\n",
    "        x, hidden = self.rnn(x, self.hidden)\n",
    "        x = x[:, -1, :] # Keep only the last output\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "\n",
    "        self.hidden = hidden.data\n",
    "\n",
    "        return x\n",
    "\n",
    "class BeHaveAlways(nn.Module):\n",
    "    def __init__(self, word):\n",
    "        super(BeHaveAlways, self).__init__()\n",
    "        self.name = \"Always_\" + word\n",
    "        self.label = BEHAVE_WORDS.index(word)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.zeros(x.size(0), BEHAVE_WORDS_SIZE)\n",
    "        x[:, self.label] = 1.0\n",
    "        return x.to(device)\n",
    "\n",
    "class BeHaveMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BeHaveMLP, self).__init__()\n",
    "        FC2_SCALE = 16\n",
    "        FC3_SCALE = 4\n",
    "\n",
    "        self.fc1 = nn.Linear(EMBEDDINGS_DIM*BEHAVE_CONTEXT_SIZE, EMBEDDINGS_DIM).to(device)\n",
    "        self.fc2 = nn.Linear(EMBEDDINGS_DIM, BEHAVE_WORDS_SIZE * FC2_SCALE).to(device)\n",
    "        self.fc3 = nn.Linear(BEHAVE_WORDS_SIZE * FC2_SCALE, BEHAVE_WORDS_SIZE * FC3_SCALE).to(device)\n",
    "        self.fc4 = nn.Linear(BEHAVE_WORDS_SIZE * FC3_SCALE, BEHAVE_WORDS_SIZE).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = embeddings[x]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = torch.log_softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "def behave_create_dataset(\n",
    "    words: list[str],\n",
    "    dataset_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a dataset from the given words.  \n",
    "    \"\"\"\n",
    "    label_to_vocabulary:dict[int, int] = {}\n",
    "\n",
    "    vocabulary_to_label = { vocabulary[word]: None for word in vocabulary.lookup_tokens(range(VOCABULARY_SIZE)) }\n",
    "\n",
    "    for label, word in enumerate(BEHAVE_WORDS):\n",
    "\n",
    "        # Skip '<unk>' to avoid bias to just guess <unk>\n",
    "        if word == '<unk>': continue\n",
    "\n",
    "        vocabulary_index = vocabulary[word]\n",
    "\n",
    "        vocabulary_to_label[vocabulary_index] = label\n",
    "        label_to_vocabulary[label] = vocabulary_index\n",
    "\n",
    "    return dataset_create(\n",
    "        words, \n",
    "        context_size_before=BEHAVE_CONTEXT_SIZE / 2, \n",
    "        context_size_after=BEHAVE_CONTEXT_SIZE / 2, \n",
    "        vocabulary_index_to_target=vocabulary_to_label, \n",
    "        dataset_name='behave.'+dataset_name\n",
    "    ), label_to_vocabulary\n",
    "\n",
    "def behave_rnn_train(\n",
    "    dataset: TensorDataset,\n",
    "    model: BeHaveRNN,\n",
    "    criterion: object,\n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> list[tuple[int, float]]: \n",
    "\n",
    "    model.name = model_nameof(model, criterion, optimizer)\n",
    "\n",
    "    if model_load(model, 'behave'):\n",
    "        return\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    # Train with different sequence lengths\n",
    "    for context_size in range(0, (BEHAVE_CONTEXT_SIZE // 2) - 1):\n",
    "        contexts = dataset.tensors[0][:,context_size:BEHAVE_CONTEXT_SIZE - context_size]\n",
    "        targets = dataset.tensors[1]\n",
    "\n",
    "        print(\"Context size:\", context_size, contexts.shape)\n",
    "        \n",
    "        losses.append(model_train(\n",
    "            model, TensorDataset(contexts, targets), criterion, optimizer, \n",
    "            model_category='behave',\n",
    "            epochs=BEHAVE_EPOCHS, \n",
    "            batch_size=BEHAVE_BATCH_SIZE,\n",
    "            tranform_targets=lambda x: torch.nn.functional.one_hot(x, num_classes=BEHAVE_WORDS_SIZE).float(),\n",
    "            retrain=True,\n",
    "            figure_tag=f'_context-{context_size}'\n",
    "        ))\n",
    "\n",
    "        model.reset()\n",
    "\n",
    "    plt.clf()\n",
    "    for i, loss in enumerate(losses):\n",
    "        plt.plot(loss, label=f'Context size {i+1}')\n",
    "    plt.title(f'{model.name} | Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(DOCS_DIR + f'loss_{model.name}.png')\n",
    "\n",
    "    model_save(model, 'behave')\n",
    "\n",
    "def behave_mlp_train(\n",
    "    dataset: TensorDataset,\n",
    "    model: BeHaveMLP,\n",
    "    criterion: object,\n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> list[tuple[int, float]]: \n",
    "    \n",
    "    model_train(\n",
    "        model, dataset, \n",
    "        criterion, \n",
    "        optimizer,\n",
    "        model_category='behave',\n",
    "        epochs=BEHAVE_EPOCHS, batch_size=BEHAVE_BATCH_SIZE,\n",
    "        tranform_targets=lambda x: torch.nn.functional.one_hot(x, num_classes=BEHAVE_WORDS_SIZE).float()\n",
    "    )\n",
    "\n",
    "def behave_performance(\n",
    "    model: nn.Module,\n",
    "    dataset: TensorDataset,\n",
    "    dataset_name: str = 'Validation'\n",
    "):\n",
    "    return model_accuracy(\n",
    "        model, dataset, dataset_name,\n",
    "        transform_outputs=lambda x: torch.argmax(x, dim=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def behave_create_model():\n",
    "\n",
    "    print(\"Training be/have models\")\n",
    "    training_data, label_to_vocabulary = behave_create_dataset(words_train, 'train')\n",
    "\n",
    "    rnn1 = BeHaveRNN()\n",
    "    behave_rnn_train(\n",
    "        training_data, rnn1, \n",
    "        nn.CrossEntropyLoss(), \n",
    "        torch.optim.Adam(rnn1.parameters(), lr=0.001)\n",
    "    )\n",
    "    \n",
    "    # rnn2 = BeHaveRNN()\n",
    "    # behave_rnn_train(\n",
    "    #     training_data, rnn2, \n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.Adam(rnn2.parameters(), lr=0.002)\n",
    "    # )\n",
    "\n",
    "    # rnn3 = BeHaveRNN()\n",
    "    # behave_rnn_train(\n",
    "    #     training_data, rnn3, \n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.Adam(rnn3.parameters(), lr=0.003)\n",
    "    # )\n",
    "\n",
    "    # rnn4 = BeHaveRNN()\n",
    "    # behave_rnn_train(\n",
    "    #     training_data, rnn4, \n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.SGD(rnn4.parameters(), lr=0.001)\n",
    "    # )\n",
    "\n",
    "    # rnn5 = BeHaveRNN()\n",
    "    # behave_rnn_train(\n",
    "    #     training_data, rnn5, \n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.SGD(rnn5.parameters(), lr=0.01)\n",
    "    # )\n",
    "\n",
    "    # rnn6 = BeHaveRNN()\n",
    "    # behave_rnn_train(\n",
    "    #     training_data, rnn6, \n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.Adam(rnn6.parameters(), lr=0.0001)\n",
    "    # )\n",
    "\n",
    "    # mlp1 = BeHaveMLP()\n",
    "    # behave_mlp_train(\n",
    "    #     training_data, mlp1,\n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.Adam(mlp1.parameters(), lr=0.001)\n",
    "    # )\n",
    "\n",
    "    # mlp2 = BeHaveMLP()\n",
    "    # behave_mlp_train(\n",
    "    #     training_data, mlp2,\n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.Adam(mlp2.parameters(), lr=0.0001)\n",
    "    # )\n",
    "\n",
    "    # mlp3 = BeHaveMLP()\n",
    "    # behave_mlp_train(\n",
    "    #     training_data, mlp3,\n",
    "    #     nn.CrossEntropyLoss(), \n",
    "    #     torch.optim.SGD(mlp3.parameters(), lr=0.0001)\n",
    "    # )\n",
    "\n",
    "    alwaysUnknown = BeHaveAlways('<unk>')\n",
    "\n",
    "    print(\"Validating be/have models\")\n",
    "\n",
    "    validation_data, _ = behave_create_dataset(words_val, 'val')\n",
    "\n",
    "    best_model, validation_accuracy = model_pick_best(\n",
    "        # [rnn1, rnn2, rnn3, rnn4, rnn5, rnn6, mlp1, mlp2, mlp3, alwaysUnknown], \n",
    "        [rnn1], \n",
    "        validation_data, \n",
    "        behave_performance,\n",
    "        figure_tag='_behave'\n",
    "    )\n",
    "\n",
    "    # test_data, _ = behave_create_dataset(words_test, 'test')\n",
    "    # test_accuracy = behave_performance(best_model, test_data, 'Test')\n",
    "    # train_accuracy = behave_performance(best_model, training_data, 'Train')\n",
    "\n",
    "    # plt.clf()\n",
    "    # plt.bar(['Train', 'Validation', 'Test'], [train_accuracy, validation_accuracy, test_accuracy])\n",
    "    # plt.title('Be/Have Model Accuracy')\n",
    "    # plt.xlabel('Dataset')\n",
    "    # plt.ylabel('Accuracy')\n",
    "    # plt.ylim(0.0, 1.0)\n",
    "    # plt.savefig(DOCS_DIR + 'accuracy_behave_best.png')\n",
    "    # plt.show()\n",
    "\n",
    "    return best_model\n",
    "     \n",
    "\n",
    "behave_model = behave_create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behave_try(before: str, after:str):\n",
    "    behave_model.to(device)\n",
    "    behave_model.eval()\n",
    "    behave_model.reset()\n",
    "    \n",
    "    words_before = TOKENIZER(before)\n",
    "    words_after = TOKENIZER(after)\n",
    "\n",
    "    if len(words_before) != len(words_after):\n",
    "        print(\"Contexts must have the same length\")\n",
    "        return\n",
    "\n",
    "    # Make context\n",
    "    context = torch.zeros(1, len(words_before) + len(words_after)).long().to(device)\n",
    "    for i, word in enumerate(words_before):\n",
    "        context[0, i] = vocabulary[word]\n",
    "    for i, word in enumerate(words_after):\n",
    "        context[0, i + len(words_before)] = vocabulary[word]\n",
    "\n",
    "    output = behave_model(context)\n",
    "    output = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    word = BEHAVE_WORDS[output]\n",
    "    \n",
    "    print(f'{before} ({word}) {after}')\n",
    "\n",
    "\n",
    "behave_try(\"When we\", \"younger we\")\n",
    "\n",
    "behave_try(\"Who\", \"you\")\n",
    "\n",
    "# From the beginning of Dracula \n",
    "# This is a text snippet from the training data, and will have a bias for success\n",
    "behave_try(\"and that as it was a national dish I should\", \"able to get it anywhere along the Carpathians I found\")\n",
    "\n",
    "behave_try(\"This ai\", \"emberrasing me\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010...\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 0 | Loss 0.0034099918543409272\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 1 | Loss 0.0027254811520971553\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 2 | Loss 0.0026602072817765035\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 3 | Loss 0.002634040010657554\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 4 | Loss 0.0026087562139017573\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 5 | Loss 0.0025808454394777845\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 6 | Loss 0.0025426337647286973\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 7 | Loss 0.0025038479497794044\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 8 | Loss 0.0024650904874325913\n",
      "Training | Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 | Epoch 9 | Loss 0.0024301633526322567\n",
      "Saved Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010 (./data/gen/Gen1Rnn_CrossEntropyLoss_Adam-lr0.0010.pt)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GEN_CONTEXT_SIZE = 5\n",
    "GEN_BATCH_SIZE = 2048\n",
    "GEN_EPOCHS = 10\n",
    "\n",
    "class Gen1Rnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Gen1Rnn, self).__init__()\n",
    "\n",
    "        self.hidden = None\n",
    "        self.rnn = nn.RNN(EMBEDDINGS_DIM, EMBEDDINGS_DIM * 8, batch_first=True)\n",
    "        self.fc1 = nn.Linear(EMBEDDINGS_DIM * 8, EMBEDDINGS_DIM * 4)\n",
    "        self.fc2 = nn.Linear(EMBEDDINGS_DIM * 4, EMBEDDINGS_DIM * 2)\n",
    "        self.fc3 = nn.Linear(EMBEDDINGS_DIM * 2, VOCABULARY_SIZE)\n",
    "\n",
    "    def reset(self):\n",
    "        self.hidden = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = embeddings[x]\n",
    "\n",
    "        # Reset the state if its incompatible with current input\n",
    "        if self.hidden is not None and self.hidden.size(1) != x.size(0):\n",
    "            self.reset()\n",
    "\n",
    "        x, hidden = self.rnn(x, self.hidden)\n",
    "        x = nn.functional.relu(x[:, -1, :]) # Keep only the last output\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        self.hidden = hidden.data\n",
    "\n",
    "        return x\n",
    "\n",
    "def gen_create_dataset(\n",
    "    words: list[str],\n",
    "    dataset_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a dataset from the given words.  \n",
    "    \"\"\"\n",
    "    vocabulary_idx_to_label = { vocabulary[word]: vocabulary[word] for word in vocabulary.lookup_tokens(range(VOCABULARY_SIZE)) }\n",
    "    vocabulary_idx_to_label[vocabulary['<unk>']] = None\n",
    "\n",
    "    return dataset_create(words, context_size_before=GEN_CONTEXT_SIZE, vocabulary_index_to_target=vocabulary_idx_to_label, dataset_name='gen.'+dataset_name)\n",
    "\n",
    "def gen_train(\n",
    "    dataset: TensorDataset,\n",
    "    model: nn.Module,\n",
    "    criterion: object,\n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> list[tuple[int, float]]: \n",
    "    \n",
    "    model_train(\n",
    "        model, dataset, criterion, optimizer, \n",
    "        model_category='gen',\n",
    "        epochs=GEN_EPOCHS, \n",
    "        batch_size=GEN_BATCH_SIZE,\n",
    "        tranform_targets=lambda x: torch.nn.functional.one_hot(x, num_classes=VOCABULARY_SIZE).float(),\n",
    "        retrain=True\n",
    "    )\n",
    "\n",
    "def gen_performance(\n",
    "    model: nn.Module,\n",
    "    dataset: TensorDataset,\n",
    "    dataset_name: str = 'Validation'\n",
    "):\n",
    "    return model_accuracy(\n",
    "        model, dataset, dataset_name,\n",
    "        transform_outputs=lambda x: torch.argmax(x, dim=1)\n",
    "    )\n",
    "\n",
    "def gen_create_model():\n",
    "\n",
    "    training_data = gen_create_dataset(words_val, 'train')\n",
    "\n",
    "    m1 = Gen1Rnn()\n",
    "    gen_train(\n",
    "        training_data, m1, \n",
    "        nn.CrossEntropyLoss(), \n",
    "        torch.optim.Adam(m1.parameters(), lr=0.001)\n",
    "    )\n",
    "\n",
    "    best_model, validation_accuracy = model_pick_best(\n",
    "        [m1], \n",
    "        training_data, \n",
    "        behave_performance,\n",
    "        figure_tag='gen'\n",
    "    )\n",
    "\n",
    "dataset = gen_create_dataset(words_val, 'val')\n",
    "\n",
    "model = Gen1Rnn()\n",
    "\n",
    "gen_train(dataset, model, nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.001))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> once upon a time , there was (the|a|his|it|my)\n",
      "> hello , my name is one and (the|a|i|and|he)\n",
      "> hello , my name is one and the (had|have|was|be|man)\n",
      "> hello , my name is one and the had (had|and|was|have|in)\n",
      "> hello , my name is one and the had had (the|a|i|it|his)\n",
      "> hello , my name is one and the had had the (had|have|was|man|be)\n",
      "> hello , my name is one and the had had a (had|have|was|man|are)\n",
      "> hello , my name is one and the had had i (was|had|have|were|is)\n",
      "> hello , my name is one and the had had it (was|had|,|and|of)\n",
      "> hello , my name is one and the had had his (had|have|was|man|be)\n",
      "> hello , my name is one and the had and (the|a|i|he|it)\n",
      "> hello , my name is one and the had and the (had|have|was|man|be)\n",
      "> hello , my name is one and the had and a (had|have|was|man|are)\n",
      "> hello , my name is one and the had and i (was|had|have|were|is)\n",
      "> hello , my name is one and the had and he (was|had|have|were|of)\n",
      "> hello , my name is one and the had and it (was|had|,|and|of)\n",
      "> hello , my name is one and the had was (the|a|his|it|my)\n",
      "> hello , my name is one and the had was the (had|have|was|man|are)\n",
      "> hello , my name is one and the had was a (had|have|was|man|are)\n",
      "> hello , my name is one and the had was his (had|have|was|man|are)\n",
      "> hello , my name is one and the had was it (,|.|of|was|had)\n",
      "> hello , my name is one and the had was my (had|have|was|man|are)\n",
      "> hello , my name is one and the had have (the|a|i|and|he)\n",
      "> hello , my name is one and the had have the (had|have|was|man|be)\n",
      "> hello , my name is one and the had have a (had|have|was|man|are)\n",
      "> hello , my name is one and the had have i (was|had|have|were|is)\n",
      "> hello , my name is one and the had have and (the|a|i|he|it)\n",
      "> hello , my name is one and the had have he (was|had|have|were|of)\n",
      "> hello , my name is one and the had in (the|a|his|it|my)\n",
      "> hello , my name is one and the had in the (had|have|was|man|are)\n",
      "> hello , my name is one and the had in a (had|have|was|man|are)\n",
      "> hello , my name is one and the had in his (had|have|was|,|man)\n",
      "> hello , my name is one and the had in it (,|.|of|was|to)\n",
      "> hello , my name is one and the had in my (had|have|was|man|are)\n",
      "> hello , my name is one and the have (had|was|and|,|have)\n",
      "> hello , my name is one and the have had (the|a|i|it|and)\n",
      "> hello , my name is one and the have had the (had|have|was|man|be)\n",
      "> hello , my name is one and the have had a (had|have|was|man|are)\n",
      "> hello , my name is one and the have had i (had|was|have|were|is)\n",
      "> hello , my name is one and the have had it (was|had|,|and|of)\n",
      "> hello , my name is one and the have had and (the|a|i|he|it)\n",
      "> hello , my name is one and the have was (the|a|his|it|my)\n",
      "> hello , my name is one and the have was the (had|have|was|man|are)\n",
      "> hello , my name is one and the have was a (had|have|was|man|are)\n",
      "> hello , my name is one and the have was his (had|have|was|man|are)\n",
      "> hello , my name is one and the have was it (,|.|of|was|had)\n",
      "> hello , my name is one and the have was my (had|have|was|man|are)\n",
      "> hello , my name is one and the have and (the|a|i|he|his)\n",
      "> hello , my name is one and the have and the (had|have|was|man|be)\n",
      "> hello , my name is one and the have and a (had|have|was|man|are)\n",
      "> hello , my name is one and the have and i (was|had|have|were|is)\n",
      "> hello , my name is one and the have and he (was|had|have|of|were)\n",
      "> hello , my name is one and the have and his (had|have|was|man|are)\n",
      "> hello , my name is one and the have , (and|i|he|it|you)\n",
      "> hello , my name is one and the have , and (i|the|he|and|a)\n",
      "> hello , my name is one and the have , i (was|had|have|were|is)\n",
      "> hello , my name is one and the have , he (was|had|have|were|of)\n",
      "> hello , my name is one and the have , it (was|had|and|have|of)\n",
      "> hello , my name is one and the have , you (was|had|have|and|were)\n",
      "> hello , my name is one and the have have (the|a|i|and|it)\n",
      "> hello , my name is one and the have have the (had|have|was|man|be)\n",
      "> hello , my name is one and the have have a (had|have|was|man|are)\n",
      "> hello , my name is one and the have have i (was|had|have|were|of)\n",
      "> hello , my name is one and the have have and (the|a|i|he|his)\n",
      "> hello , my name is one and the have have it (was|,|had|.|of)\n",
      "> hello , my name is one and the was (the|a|,|.|in)\n",
      "> hello , my name is one and the was the (had|have|was|man|are)\n",
      "> hello , my name is one and the was the had (had|and|was|have|in)\n",
      "> hello , my name is one and the was the have (had|was|,|and|have)\n",
      "> hello , my name is one and the was the was (the|,|.|a|in)\n",
      "> hello , my name is one and the was the man (,|.|of|was|had)\n",
      "> hello , my name is one and the was the are (,|.|of|and|to)\n",
      "> hello , my name is one and the was a (had|have|was|man|are)\n",
      "> hello , my name is one and the was a had (had|have|and|was|in)\n",
      "> hello , my name is one and the was a have (had|was|,|have|and)\n",
      "> hello , my name is one and the was a was (,|the|.|a|in)\n",
      "> hello , my name is one and the was a man (,|.|of|was|had)\n",
      "> hello , my name is one and the was a are (,|.|of|in|had)\n",
      "> hello , my name is one and the was , (and|i|he|it|you)\n",
      "> hello , my name is one and the was , and (the|i|he|and|a)\n",
      "> hello , my name is one and the was , i (was|had|have|were|is)\n",
      "> hello , my name is one and the was , he (was|had|have|were|of)\n",
      "> hello , my name is one and the was , it (was|had|,|and|of)\n",
      "> hello , my name is one and the was , you (was|had|have|and|,)\n",
      "> hello , my name is one and the was . (i|he|and|the|it)\n",
      "> hello , my name is one and the was . i (was|had|have|were|is)\n",
      "> hello , my name is one and the was . he (was|had|have|were|of)\n",
      "> hello , my name is one and the was . and (i|he|and|the|it)\n",
      "> hello , my name is one and the was . the (had|have|was|man|are)\n",
      "> hello , my name is one and the was . it (was|had|have|and|of)\n",
      "> hello , my name is one and the was in (the|a|his|my|it)\n",
      "> hello , my name is one and the was in the (had|have|was|man|are)\n",
      "> hello , my name is one and the was in a (had|have|was|man|are)\n",
      "> hello , my name is one and the was in his (had|have|was|,|.)\n",
      "> hello , my name is one and the was in my (had|have|was|man|are)\n",
      "> hello , my name is one and the was in it (.|,|of|to|was)\n",
      "> hello , my name is one and the be (,|.|of|had|was)\n",
      "> hello , my name is one and the be , (and|i|he|it|you)\n",
      "> hello , my name is one and the be , and (the|i|he|a|and)\n",
      "> hello , my name is one and the be , i (was|had|have|were|is)\n",
      "> hello , my name is one and the be , he (was|had|have|were|of)\n",
      "> hello , my name is one and the be , it (was|had|,|and|of)\n",
      "> hello , my name is one and the be , you (was|had|have|,|and)\n",
      "> hello , my name is one and the be . (i|he|and|the|it)\n",
      "> hello , my name is one and the be . i (was|had|have|were|is)\n",
      "> hello , my name is one and the be . he (was|had|have|were|of)\n",
      "> hello , my name is one and the be . and (i|he|the|and|it)\n",
      "> hello , my name is one and the be . the (had|have|was|man|are)\n",
      "> hello , my name is one and the be . it (was|had|have|and|of)\n",
      "> hello , my name is one and the be of (the|a|his|my|it)\n",
      "> hello , my name is one and the be of the (had|have|was|man|are)\n",
      "> hello , my name is one and the be of a (had|have|was|man|are)\n",
      "> hello , my name is one and the be of his (had|have|was|,|.)\n",
      "> hello , my name is one and the be of my (had|have|was|man|are)\n",
      "> hello , my name is one and the be of it (.|,|of|to|was)\n",
      "> hello , my name is one and the be had (the|a|and|i|it)\n",
      "> hello , my name is one and the be had the (had|have|was|be|man)\n",
      "> hello , my name is one and the be had a (had|have|was|man|are)\n",
      "> hello , my name is one and the be had and (the|a|i|he|his)\n",
      "> hello , my name is one and the be had i (had|was|have|were|of)\n",
      "> hello , my name is one and the be had it (,|was|.|of|had)\n",
      "> hello , my name is one and the be was (the|a|,|.|his)\n",
      "> hello , my name is one and the be was the (had|have|was|man|are)\n",
      "> hello , my name is one and the be was a (had|have|was|man|are)\n",
      "> hello , my name is one and the be was , (and|i|he|it|you)\n",
      "> hello , my name is one and the be was . (i|he|and|the|it)\n",
      "> hello , my name is one and the be was his (had|have|was|,|man)\n",
      "> hello , my name is one and the man (,|.|of|was|had)\n",
      "> hello , my name is one and the man , (and|i|he|it|you)\n",
      "> hello , my name is one and the man , and (the|i|he|a|and)\n",
      "> hello , my name is one and the man , i (was|had|have|were|is)\n",
      "> hello , my name is one and the man , he (was|had|have|were|of)\n",
      "> hello , my name is one and the man , it (was|had|and|,|of)\n",
      "> hello , my name is one and the man , you (was|had|have|and|of)\n",
      "> hello , my name is one and the man . (i|he|and|the|it)\n",
      "> hello , my name is one and the man . i (was|had|have|were|is)\n",
      "> hello , my name is one and the man . he (was|had|have|were|of)\n",
      "> hello , my name is one and the man . and (i|he|the|and|it)\n",
      "> hello , my name is one and the man . the (had|have|was|man|are)\n",
      "> hello , my name is one and the man . it (was|had|and|have|of)\n",
      "> hello , my name is one and the man of (the|a|his|my|it)\n",
      "> hello , my name is one and the man of the (had|have|was|man|are)\n",
      "> hello , my name is one and the man of a (had|have|was|man|are)\n",
      "> hello , my name is one and the man of his (had|have|was|,|.)\n",
      "> hello , my name is one and the man of my (had|have|was|man|are)\n",
      "> hello , my name is one and the man of it (.|,|of|to|was)\n",
      "> hello , my name is one and the man was (the|a|his|,|.)\n",
      "> hello , my name is one and the man was the (had|have|was|man|are)\n",
      "> hello , my name is one and the man was a (had|have|was|man|are)\n",
      "> hello , my name is one and the man was his (had|have|was|man|,)\n",
      "> hello , my name is one and the man was , (and|i|he|it|you)\n",
      "> hello , my name is one and the man was . (i|he|the|and|it)\n",
      "> hello , my name is one and the man had (the|a|and|i|it)\n",
      "> hello , my name is one and the man had the (had|have|was|be|man)\n",
      "> hello , my name is one and the man had a (had|have|was|man|are)\n",
      "> hello , my name is one and the man had and (the|a|i|he|his)\n",
      "> hello , my name is one and the man had i (had|was|have|were|are)\n",
      "> hello , my name is one and the man had it (was|,|.|of|had)\n",
      "> hello , my name is one and a (had|have|was|man|are)\n",
      "> hello , my name is one and a had (had|and|have|was|in)\n",
      "> hello , my name is one and a had had (the|a|i|it|and)\n",
      "> hello , my name is one and a had had the (had|have|was|man|be)\n",
      "> hello , my name is one and a had had a (had|have|was|man|are)\n",
      "> hello , my name is one and a had had i (was|had|have|were|is)\n",
      "> hello , my name is one and a had had it (was|had|,|and|of)\n",
      "> hello , my name is one and a had had and (the|a|i|he|it)\n",
      "> hello , my name is one and a had and (the|a|i|he|it)\n",
      "> hello , my name is one and a had and the (had|have|was|man|be)\n",
      "> hello , my name is one and a had and a (had|have|was|man|are)\n",
      "> hello , my name is one and a had and i (was|had|have|were|is)\n",
      "> hello , my name is one and a had and he (was|had|have|of|were)\n",
      "> hello , my name is one and a had and it (was|had|,|of|.)\n",
      "> hello , my name is one and a had have (the|a|i|his|it)\n",
      "> hello , my name is one and a had have the (had|have|was|man|be)\n",
      "> hello , my name is one and a had have a (had|have|was|man|are)\n",
      "> hello , my name is one and a had have i (was|had|have|were|of)\n",
      "> hello , my name is one and a had have his (had|have|was|man|be)\n",
      "> hello , my name is one and a had have it (was|,|had|.|of)\n",
      "> hello , my name is one and a had was (the|a|his|it|my)\n",
      "> hello , my name is one and a had was the (had|have|was|man|are)\n",
      "> hello , my name is one and a had was a (had|have|was|man|are)\n",
      "> hello , my name is one and a had was his (had|have|was|man|are)\n",
      "> hello , my name is one and a had was it (,|.|of|was|had)\n",
      "> hello , my name is one and a had was my (had|have|was|man|are)\n",
      "> hello , my name is one and a had in (the|a|his|it|my)\n",
      "> hello , my name is one and a had in the (had|have|was|man|are)\n",
      "> hello , my name is one and a had in a (had|have|was|man|are)\n",
      "> hello , my name is one and a had in his (had|have|was|,|man)\n",
      "> hello , my name is one and a had in it (,|.|of|was|to)\n",
      "> hello , my name is one and a had in my (had|have|was|man|are)\n",
      "> hello , my name is one and a have (had|was|have|,|and)\n",
      "> hello , my name is one and a have had (the|a|i|and|it)\n",
      "> hello , my name is one and a have had the (had|have|was|man|be)\n",
      "> hello , my name is one and a have had a (had|have|was|man|are)\n",
      "> hello , my name is one and a have had i (was|had|have|were|is)\n",
      "> hello , my name is one and a have had and (the|a|i|he|it)\n",
      "> hello , my name is one and a have had it (was|had|,|.|and)\n",
      "> hello , my name is one and a have was (the|a|his|it|my)\n",
      "> hello , my name is one and a have was the (had|have|was|man|are)\n",
      "> hello , my name is one and a have was a (had|have|was|man|are)\n",
      "> hello , my name is one and a have was his (had|have|was|man|,)\n",
      "> hello , my name is one and a have was it (,|.|of|was|had)\n",
      "> hello , my name is one and a have was my (had|have|was|man|are)\n",
      "> hello , my name is one and a have have (the|a|i|and|his)\n",
      "> hello , my name is one and a have have the (had|have|was|man|be)\n",
      "> hello , my name is one and a have have a (had|have|was|man|are)\n",
      "> hello , my name is one and a have have i (was|had|have|were|of)\n",
      "> hello , my name is one and a have have and (the|a|i|he|his)\n",
      "> hello , my name is one and a have have his (had|have|was|man|be)\n",
      "> hello , my name is one and a have , (and|i|he|it|you)\n",
      "> hello , my name is one and a have , and (i|the|he|and|a)\n",
      "> hello , my name is one and a have , i (was|had|have|were|is)\n",
      "> hello , my name is one and a have , he (was|had|have|were|of)\n",
      "> hello , my name is one and a have , it (was|had|and|have|of)\n",
      "> hello , my name is one and a have , you (was|had|have|and|were)\n",
      "> hello , my name is one and a have and (the|a|i|he|his)\n",
      "> hello , my name is one and a have and the (had|have|was|man|be)\n",
      "> hello , my name is one and a have and a (had|have|was|man|are)\n",
      "> hello , my name is one and a have and i (was|had|have|were|of)\n",
      "> hello , my name is one and a have and he (was|had|have|of|were)\n",
      "> hello , my name is one and a have and his (had|have|was|man|are)\n",
      "> hello , my name is one and a was (the|,|a|.|in)\n",
      "> hello , my name is one and a was the (had|have|was|man|are)\n",
      "> hello , my name is one and a was the had (had|and|was|have|in)\n",
      "> hello , my name is one and a was the have (had|was|,|and|have)\n",
      "> hello , my name is one and a was the was (the|,|.|a|in)\n",
      "> hello , my name is one and a was the man (,|.|of|was|had)\n",
      "> hello , my name is one and a was the are (,|.|of|and|to)\n",
      "> hello , my name is one and a was , (and|i|he|it|you)\n",
      "> hello , my name is one and a was , and (the|i|he|and|a)\n",
      "> hello , my name is one and a was , i (was|had|have|were|is)\n",
      "> hello , my name is one and a was , he (was|had|have|were|of)\n",
      "> hello , my name is one and a was , it (was|had|,|and|of)\n",
      "> hello , my name is one and a was , you (was|had|have|and|,)\n",
      "> hello , my name is one and a was a (had|have|was|man|are)\n",
      "> hello , my name is one and a was a had (had|have|and|was|in)\n",
      "> hello , my name is one and a was a have (had|was|,|have|and)\n",
      "> hello , my name is one and a was a was (,|the|.|a|in)\n",
      "> hello , my name is one and a was a man (,|.|of|was|had)\n",
      "> hello , my name is one and a was a are (,|.|of|in|had)\n",
      "> hello , my name is one and a was . (i|he|and|the|it)\n",
      "> hello , my name is one and a was . i (was|had|have|were|is)\n",
      "> hello , my name is one and a was . he (was|had|have|were|of)\n",
      "> hello , my name is one and a was . and (i|he|and|the|it)\n",
      "> hello , my name is one and a was . the (had|have|was|man|are)\n",
      "> hello , my name is one and a was . it (was|had|have|and|of)\n",
      "> hello , my name is one and a was in (the|a|his|my|it)\n",
      "> hello , my name is one and a was in the (had|have|was|man|are)\n",
      "> hello , my name is one and a was in a (had|have|was|man|are)\n",
      "> hello , my name is one and a was in his (had|have|was|,|.)\n",
      "> hello , my name is one and a was in my (had|have|was|man|are)\n",
      "> hello , my name is one and a was in it (.|,|of|to|was)\n",
      "> hello , my name is one and a man (,|.|of|was|had)\n",
      "> hello , my name is one and a man , (and|i|he|it|you)\n",
      "> hello , my name is one and a man , and (the|i|he|a|and)\n",
      "> hello , my name is one and a man , i (was|had|have|were|is)\n",
      "> hello , my name is one and a man , he (was|had|have|were|of)\n",
      "> hello , my name is one and a man , it (was|had|and|,|of)\n",
      "> hello , my name is one and a man , you (was|had|have|and|of)\n",
      "> hello , my name is one and a man . (i|he|and|the|it)\n",
      "> hello , my name is one and a man . i (was|had|have|were|is)\n",
      "> hello , my name is one and a man . he (was|had|have|were|of)\n",
      "> hello , my name is one and a man . and (i|he|the|and|it)\n",
      "> hello , my name is one and a man . the (had|have|was|man|are)\n",
      "> hello , my name is one and a man . it (was|had|and|have|of)\n",
      "> hello , my name is one and a man of (the|a|his|my|it)\n",
      "> hello , my name is one and a man of the (had|have|was|man|are)\n",
      "> hello , my name is one and a man of a (had|have|was|man|are)\n",
      "> hello , my name is one and a man of his (had|have|was|,|.)\n",
      "> hello , my name is one and a man of my (had|have|was|man|are)\n",
      "> hello , my name is one and a man of it (.|,|of|to|was)\n",
      "> hello , my name is one and a man was (the|a|his|,|.)\n",
      "> hello , my name is one and a man was the (had|have|was|man|are)\n",
      "> hello , my name is one and a man was a (had|have|was|man|are)\n",
      "> hello , my name is one and a man was his (had|have|was|man|,)\n",
      "> hello , my name is one and a man was , (and|i|he|it|you)\n",
      "> hello , my name is one and a man was . (i|he|the|and|it)\n",
      "> hello , my name is one and a man had (the|a|and|i|it)\n",
      "> hello , my name is one and a man had the (had|have|was|be|man)\n",
      "> hello , my name is one and a man had a (had|have|was|man|are)\n",
      "> hello , my name is one and a man had and (the|a|i|he|his)\n",
      "> hello , my name is one and a man had i (had|was|have|were|are)\n",
      "> hello , my name is one and a man had it (was|,|.|of|had)\n",
      "> hello , my name is one and a are (,|.|of|had|in)\n",
      "> hello , my name is one and a are , (and|i|he|it|you)\n",
      "> hello , my name is one and a are , and (the|i|he|and|a)\n",
      "> hello , my name is one and a are , i (was|had|have|were|is)\n",
      "> hello , my name is one and a are , he (was|had|have|were|of)\n",
      "> hello , my name is one and a are , it (was|had|and|,|of)\n",
      "> hello , my name is one and a are , you (was|had|have|and|of)\n",
      "> hello , my name is one and a are . (i|he|and|the|it)\n",
      "> hello , my name is one and a are . i (was|had|have|were|is)\n",
      "> hello , my name is one and a are . he (was|had|have|were|of)\n",
      "> hello , my name is one and a are . and (i|he|the|and|it)\n",
      "> hello , my name is one and a are . the (had|have|was|man|are)\n",
      "> hello , my name is one and a are . it (was|had|have|and|of)\n",
      "> hello , my name is one and a are of (the|a|his|my|it)\n",
      "> hello , my name is one and a are of the (had|have|was|man|are)\n",
      "> hello , my name is one and a are of a (had|have|was|man|are)\n",
      "> hello , my name is one and a are of his (had|have|was|,|.)\n",
      "> hello , my name is one and a are of my (had|have|was|man|are)\n",
      "> hello , my name is one and a are of it (.|,|of|was|to)\n",
      "> hello , my name is one and a are had (the|a|and|i|it)\n",
      "> hello , my name is one and a are had the (had|have|was|be|man)\n",
      "> hello , my name is one and a are had a (had|have|was|man|are)\n",
      "> hello , my name is one and a are had and (the|a|i|he|his)\n",
      "> hello , my name is one and a are had i (had|was|have|were|of)\n",
      "> hello , my name is one and a are had it (was|,|.|of|had)\n",
      "> hello , my name is one and a are in (the|a|his|my|it)\n",
      "> hello , my name is one and a are in the (had|have|was|man|are)\n",
      "> hello , my name is one and a are in a (had|have|was|man|are)\n",
      "> hello , my name is one and a are in his (had|have|was|,|.)\n",
      "> hello , my name is one and a are in my (had|have|was|man|are)\n",
      "> hello , my name is one and a are in it (.|,|of|to|was)\n",
      "> hello , my name is one and i (was|had|have|were|of)\n",
      "> hello , my name is one and i was (the|a|his|,|.)\n",
      "> hello , my name is one and i was the (had|have|was|man|are)\n",
      "> hello , my name is one and i was the had (had|and|was|have|in)\n",
      "> hello , my name is one and i was the have (had|was|,|and|have)\n",
      "> hello , my name is one and i was the was (the|,|.|a|in)\n",
      "> hello , my name is one and i was the man (.|,|of|was|had)\n",
      "> hello , my name is one and i was the are (,|.|of|to|and)\n",
      "> hello , my name is one and i was a (had|have|was|man|are)\n",
      "> hello , my name is one and i was a had (had|have|and|was|in)\n",
      "> hello , my name is one and i was a have (had|was|,|have|and)\n",
      "> hello , my name is one and i was a was (,|the|.|a|in)\n",
      "> hello , my name is one and i was a man (.|,|of|was|had)\n",
      "> hello , my name is one and i was a are (,|.|of|in|to)\n",
      "> hello , my name is one and i was his (had|have|was|man|are)\n",
      "> hello , my name is one and i was his had (had|and|was|,|in)\n",
      "> hello , my name is one and i was his have (,|.|had|and|in)\n",
      "> hello , my name is one and i was his was (the|,|.|a|to)\n",
      "> hello , my name is one and i was his man (.|,|of|to|was)\n",
      "> hello , my name is one and i was his are (.|,|of|to|in)\n",
      "> hello , my name is one and i was , (and|i|he|it|you)\n",
      "> hello , my name is one and i was , and (the|i|he|and|a)\n",
      "> hello , my name is one and i was , i (was|had|have|were|is)\n",
      "> hello , my name is one and i was , he (was|had|have|were|of)\n",
      "> hello , my name is one and i was , it (was|had|,|and|of)\n",
      "> hello , my name is one and i was , you (was|had|have|,|and)\n",
      "> hello , my name is one and i was . (i|he|the|and|it)\n",
      "> hello , my name is one and i was . i (was|had|have|were|is)\n",
      "> hello , my name is one and i was . he (was|had|have|were|of)\n",
      "> hello , my name is one and i was . the (had|have|was|man|are)\n",
      "> hello , my name is one and i was . and (i|he|and|the|it)\n",
      "> hello , my name is one and i was . it (was|had|have|and|of)\n",
      "> hello , my name is one and i had (the|a|and|i|it)\n",
      "> hello , my name is one and i had the (had|have|was|be|man)\n",
      "> hello , my name is one and i had the had (had|and|was|have|in)\n",
      "> hello , my name is one and i had the have (had|was|and|,|in)\n",
      "> hello , my name is one and i had the was (the|a|,|.|in)\n",
      "> hello , my name is one and i had the be (,|.|of|had|was)\n",
      "> hello , my name is one and i had the man (,|.|of|was|had)\n",
      "> hello , my name is one and i had a (had|have|was|man|are)\n",
      "> hello , my name is one and i had a had (had|and|have|was|in)\n",
      "> hello , my name is one and i had a have (had|was|,|and|have)\n",
      "> hello , my name is one and i had a was (the|,|a|.|in)\n",
      "> hello , my name is one and i had a man (,|.|of|was|had)\n",
      "> hello , my name is one and i had a are (,|.|of|had|in)\n",
      "> hello , my name is one and i had and (the|a|i|he|his)\n",
      "> hello , my name is one and i had and the (had|have|was|man|be)\n",
      "> hello , my name is one and i had and a (had|have|was|man|are)\n",
      "> hello , my name is one and i had and i (was|had|have|were|of)\n",
      "> hello , my name is one and i had and he (was|had|have|of|were)\n",
      "> hello , my name is one and i had and his (had|have|was|man|are)\n",
      "> hello , my name is one and i had i (had|was|have|were|are)\n",
      "> hello , my name is one and i had i had (the|a|and|i|it)\n",
      "> hello , my name is one and i had i was (the|a|his|,|.)\n",
      "> hello , my name is one and i had i have (the|a|and|it|i)\n",
      "> hello , my name is one and i had i were (the|a|,|in|his)\n",
      "> hello , my name is one and i had i are (the|a|,|.|and)\n",
      "> hello , my name is one and i had it (was|,|had|and|.)\n",
      "> hello , my name is one and i had it was (the|a|his|it|my)\n",
      "> hello , my name is one and i had it , (and|i|he|it|you)\n",
      "> hello , my name is one and i had it had (the|a|i|and|he)\n",
      "> hello , my name is one and i had it and (the|i|a|he|and)\n",
      "> hello , my name is one and i had it . (i|he|and|the|it)\n",
      "> hello , my name is one and i have (the|a|and|it|his)\n",
      "> hello , my name is one and i have the (had|have|was|be|man)\n",
      "> hello , my name is one and i have the had (had|and|was|have|in)\n",
      "> hello , my name is one and i have the have (had|was|and|,|in)\n",
      "> hello , my name is one and i have the was (the|a|,|.|in)\n",
      "> hello , my name is one and i have the be (,|.|of|had|was)\n",
      "> hello , my name is one and i have the man (,|.|of|was|had)\n",
      "> hello , my name is one and i have a (had|have|was|man|are)\n",
      "> hello , my name is one and i have a had (had|and|have|was|in)\n",
      "> hello , my name is one and i have a have (had|was|,|have|and)\n",
      "> hello , my name is one and i have a was (the|,|a|.|in)\n",
      "> hello , my name is one and i have a man (,|.|of|was|had)\n",
      "> hello , my name is one and i have a are (,|.|of|in|had)\n",
      "> hello , my name is one and i have and (the|a|i|he|his)\n",
      "> hello , my name is one and i have and the (had|have|was|man|be)\n",
      "> hello , my name is one and i have and a (had|have|was|man|are)\n",
      "> hello , my name is one and i have and i (was|had|have|were|of)\n",
      "> hello , my name is one and i have and he (was|had|have|of|were)\n",
      "> hello , my name is one and i have and his (had|have|was|man|are)\n",
      "> hello , my name is one and i have it (was|,|.|of|had)\n",
      "> hello , my name is one and i have it was (the|a|his|it|my)\n",
      "> hello , my name is one and i have it , (and|i|he|it|you)\n",
      "> hello , my name is one and i have it . (i|he|and|the|it)\n",
      "> hello , my name is one and i have it of (the|a|his|my|it)\n",
      "> hello , my name is one and i have it had (the|a|i|and|he)\n",
      "> hello , my name is one and i have his (had|have|was|be|man)\n",
      "> hello , my name is one and i have his had (had|and|was|have|in)\n",
      "> hello , my name is one and i have his have (,|had|and|.|was)\n",
      "> hello , my name is one and i have his was (the|,|.|a|to)\n",
      "> hello , my name is one and i have his be (.|,|of|had|to)\n",
      "> hello , my name is one and i have his man (.|,|of|was|to)\n",
      "> hello , my name is one and i were (the|a|,|.|his)\n",
      "> hello , my name is one and i were the (had|have|was|man|are)\n",
      "> hello , my name is one and i were the had (had|and|was|have|in)\n",
      "> hello , my name is one and i were the have (had|was|,|and|have)\n",
      "> hello , my name is one and i were the was (the|,|.|a|in)\n",
      "> hello , my name is one and i were the man (,|.|of|was|had)\n",
      "> hello , my name is one and i were the are (,|.|of|to|and)\n",
      "> hello , my name is one and i were a (had|have|was|man|are)\n",
      "> hello , my name is one and i were a had (had|have|and|was|in)\n",
      "> hello , my name is one and i were a have (had|was|,|have|and)\n",
      "> hello , my name is one and i were a was (,|the|.|a|in)\n",
      "> hello , my name is one and i were a man (.|,|of|was|had)\n",
      "> hello , my name is one and i were a are (,|.|of|in|to)\n",
      "> hello , my name is one and i were , (and|i|he|it|you)\n",
      "> hello , my name is one and i were , and (the|i|he|and|a)\n",
      "> hello , my name is one and i were , i (was|had|have|were|is)\n",
      "> hello , my name is one and i were , he (was|had|have|were|of)\n",
      "> hello , my name is one and i were , it (was|had|,|and|of)\n",
      "> hello , my name is one and i were , you (was|had|have|,|and)\n",
      "> hello , my name is one and i were . (i|he|the|and|it)\n",
      "> hello , my name is one and i were . i (was|had|have|were|is)\n",
      "> hello , my name is one and i were . he (was|had|have|were|of)\n",
      "> hello , my name is one and i were . the (had|have|was|man|are)\n",
      "> hello , my name is one and i were . and (i|he|and|the|it)\n",
      "> hello , my name is one and i were . it (was|had|have|and|of)\n",
      "> hello , my name is one and i were his (had|have|was|man|are)\n",
      "> hello , my name is one and i were his had (had|and|was|in|have)\n",
      "> hello , my name is one and i were his have (,|.|had|and|in)\n",
      "> hello , my name is one and i were his was (the|,|.|a|to)\n",
      "> hello , my name is one and i were his man (.|,|of|to|was)\n",
      "> hello , my name is one and i were his are (.|,|of|to|in)\n",
      "> hello , my name is one and i of (the|a|his|my|it)\n",
      "> hello , my name is one and i of the (had|have|was|man|are)\n",
      "> hello , my name is one and i of the had (had|and|was|have|in)\n",
      "> hello , my name is one and i of the have (had|was|,|and|have)\n",
      "> hello , my name is one and i of the was (the|,|.|a|in)\n",
      "> hello , my name is one and i of the man (.|,|of|was|had)\n",
      "> hello , my name is one and i of the are (,|.|of|to|and)\n",
      "> hello , my name is one and i of a (had|have|was|man|are)\n",
      "> hello , my name is one and i of a had (had|have|was|and|in)\n",
      "> hello , my name is one and i of a have (had|was|,|have|and)\n",
      "> hello , my name is one and i of a was (,|.|the|a|in)\n",
      "> hello , my name is one and i of a man (.|,|of|was|had)\n",
      "> hello , my name is one and i of a are (,|.|of|in|to)\n",
      "> hello , my name is one and i of his (had|have|was|,|man)\n",
      "> hello , my name is one and i of his had (had|and|was|,|have)\n",
      "> hello , my name is one and i of his have (,|.|had|of|and)\n",
      "> hello , my name is one and i of his was (.|,|the|a|to)\n",
      "> hello , my name is one and i of his , (and|i|he|was|it)\n",
      "> hello , my name is one and i of his man (.|,|of|to|was)\n",
      "> hello , my name is one and i of my (had|have|was|man|are)\n",
      "> hello , my name is one and i of my had (had|and|was|have|in)\n",
      "> hello , my name is one and i of my have (had|was|,|and|in)\n",
      "> hello , my name is one and i of my was (the|,|.|a|in)\n",
      "> hello , my name is one and i of my man (.|,|of|was|to)\n",
      "> hello , my name is one and i of my are (.|,|of|to|in)\n",
      "> hello , my name is one and i of it (,|.|of|was|to)\n",
      "> hello , my name is one and i of it , (and|i|he|it|you)\n",
      "> hello , my name is one and i of it . (i|he|and|the|it)\n",
      "> hello , my name is one and i of it of (the|a|his|my|it)\n",
      "> hello , my name is one and i of it was (the|a|his|,|.)\n",
      "> hello , my name is one and i of it to (the|a|his|my|it)\n",
      "> hello , my name is one and and (the|a|i|he|it)\n",
      "> hello , my name is one and and the (had|have|was|man|be)\n",
      "> hello , my name is one and and the had (had|and|was|have|in)\n",
      "> hello , my name is one and and the had had (the|a|i|it|his)\n",
      "> hello , my name is one and and the had and (the|a|i|he|it)\n",
      "> hello , my name is one and and the had was (the|a|his|it|my)\n",
      "> hello , my name is one and and the had have (the|a|i|and|he)\n",
      "> hello , my name is one and and the had in (the|a|his|it|my)\n",
      "> hello , my name is one and and the have (had|was|and|have|,)\n",
      "> hello , my name is one and and the have had (the|a|i|it|and)\n",
      "> hello , my name is one and and the have was (the|a|his|it|my)\n",
      "> hello , my name is one and and the have and (the|a|i|he|his)\n",
      "> hello , my name is one and and the have have (the|a|i|and|he)\n",
      "> hello , my name is one and and the have , (and|i|he|it|you)\n",
      "> hello , my name is one and and the was (the|a|,|.|in)\n",
      "> hello , my name is one and and the was the (had|have|was|man|are)\n",
      "> hello , my name is one and and the was a (had|have|was|man|are)\n",
      "> hello , my name is one and and the was , (and|i|he|it|you)\n",
      "> hello , my name is one and and the was . (i|he|and|the|it)\n",
      "> hello , my name is one and and the was in (the|a|his|my|it)\n",
      "> hello , my name is one and and the man (,|.|of|was|had)\n",
      "> hello , my name is one and and the man , (and|i|he|it|you)\n",
      "> hello , my name is one and and the man . (i|he|and|the|it)\n",
      "> hello , my name is one and and the man of (the|a|his|my|it)\n",
      "> hello , my name is one and and the man was (the|a|his|,|.)\n",
      "> hello , my name is one and and the man had (the|a|and|i|it)\n",
      "> hello , my name is one and and the be (,|.|of|had|was)\n",
      "> hello , my name is one and and the be , (and|i|he|it|you)\n",
      "> hello , my name is one and and the be . (i|he|and|the|it)\n",
      "> hello , my name is one and and the be of (the|a|his|my|it)\n",
      "> hello , my name is one and and the be had (the|a|and|i|it)\n",
      "> hello , my name is one and and the be was (the|a|,|his|.)\n",
      "> hello , my name is one and and a (had|have|was|man|are)\n",
      "> hello , my name is one and and a had (had|and|have|was|in)\n",
      "> hello , my name is one and and a had had (the|a|i|and|it)\n",
      "> hello , my name is one and and a had and (the|a|i|he|it)\n",
      "> hello , my name is one and and a had have (the|a|i|his|and)\n",
      "> hello , my name is one and and a had was (the|a|his|it|my)\n",
      "> hello , my name is one and and a had in (the|a|his|it|my)\n",
      "> hello , my name is one and and a have (had|was|have|and|,)\n",
      "> hello , my name is one and and a have had (the|a|i|and|it)\n",
      "> hello , my name is one and and a have was (the|a|his|it|my)\n",
      "> hello , my name is one and and a have have (the|a|i|and|it)\n",
      "> hello , my name is one and and a have and (the|a|i|he|his)\n",
      "> hello , my name is one and and a have , (and|i|he|it|you)\n",
      "> hello , my name is one and and a was (the|a|,|.|in)\n",
      "> hello , my name is one and and a was the (had|have|was|man|are)\n",
      "> hello , my name is one and and a was a (had|have|was|man|are)\n",
      "> hello , my name is one and and a was , (and|i|he|it|you)\n",
      "> hello , my name is one and and a was . (i|he|and|the|it)\n",
      "> hello , my name is one and and a was in (the|a|his|my|it)\n",
      "> hello , my name is one and and a man (,|.|of|was|had)\n",
      "> hello , my name is one and and a man , (and|i|he|it|you)\n",
      "> hello , my name is one and and a man . (i|he|and|the|it)\n",
      "> hello , my name is one and and a man of (the|a|his|my|it)\n",
      "> hello , my name is one and and a man was (the|a|his|,|.)\n",
      "> hello , my name is one and and a man had (the|a|and|i|it)\n",
      "> hello , my name is one and and a are (,|.|had|of|in)\n",
      "> hello , my name is one and and a are , (and|i|he|it|you)\n",
      "> hello , my name is one and and a are . (i|he|and|the|it)\n",
      "> hello , my name is one and and a are had (the|a|and|i|it)\n",
      "> hello , my name is one and and a are of (the|a|his|my|it)\n",
      "> hello , my name is one and and a are in (the|a|his|my|it)\n",
      "> hello , my name is one and and i (was|had|have|were|is)\n",
      "> hello , my name is one and and i was (the|a|his|,|it)\n",
      "> hello , my name is one and and i was the (had|have|was|man|are)\n",
      "> hello , my name is one and and i was a (had|have|was|man|are)\n",
      "> hello , my name is one and and i was his (had|have|was|man|are)\n",
      "> hello , my name is one and and i was , (and|i|he|it|you)\n",
      "> hello , my name is one and and i was it (,|.|of|was|had)\n",
      "> hello , my name is one and and i had (the|a|and|i|it)\n",
      "> hello , my name is one and and i had the (had|have|was|be|man)\n",
      "> hello , my name is one and and i had a (had|have|was|man|are)\n",
      "> hello , my name is one and and i had and (the|a|i|he|his)\n",
      "> hello , my name is one and and i had i (had|was|have|were|are)\n",
      "> hello , my name is one and and i had it (was|had|,|and|of)\n",
      "> hello , my name is one and and i have (the|a|and|it|i)\n",
      "> hello , my name is one and and i have the (had|have|was|be|man)\n",
      "> hello , my name is one and and i have a (had|have|was|man|are)\n",
      "> hello , my name is one and and i have and (the|a|i|he|his)\n",
      "> hello , my name is one and and i have it (was|,|had|.|of)\n",
      "> hello , my name is one and and i have i (had|was|have|were|are)\n",
      "> hello , my name is one and and i were (the|a|,|in|and)\n",
      "> hello , my name is one and and i were the (had|have|was|man|be)\n",
      "> hello , my name is one and and i were a (had|have|was|man|are)\n",
      "> hello , my name is one and and i were , (and|i|he|it|you)\n",
      "> hello , my name is one and and i were in (the|a|his|my|it)\n",
      "> hello , my name is one and and i were and (the|a|i|his|he)\n",
      "> hello , my name is one and and i is (the|a|his|,|.)\n",
      "> hello , my name is one and and i is the (had|have|was|man|be)\n",
      "> hello , my name is one and and i is a (had|have|was|man|are)\n",
      "> hello , my name is one and and i is his (had|have|was|man|are)\n",
      "> hello , my name is one and and i is , (and|i|he|it|you)\n",
      "> hello , my name is one and and i is . (i|he|the|and|it)\n",
      "> hello , my name is one and and he (was|had|have|of|were)\n",
      "> hello , my name is one and and he was (the|a|his|,|.)\n",
      "> hello , my name is one and and he was the (had|have|was|man|are)\n",
      "> hello , my name is one and and he was a (had|have|was|man|are)\n",
      "> hello , my name is one and and he was his (had|have|was|man|are)\n",
      "> hello , my name is one and and he was , (and|i|he|it|you)\n",
      "> hello , my name is one and and he was . (i|he|the|and|it)\n",
      "> hello , my name is one and and he had (the|a|and|i|it)\n",
      "> hello , my name is one and and he had the (had|have|was|be|man)\n",
      "> hello , my name is one and and he had a (had|have|was|man|are)\n",
      "> hello , my name is one and and he had and (the|a|i|he|his)\n",
      "> hello , my name is one and and he had i (had|was|have|were|are)\n",
      "> hello , my name is one and and he had it (was|had|,|and|.)\n",
      "> hello , my name is one and and he have (the|a|and|it|his)\n",
      "> hello , my name is one and and he have the (had|have|was|be|man)\n",
      "> hello , my name is one and and he have a (had|have|was|man|are)\n",
      "> hello , my name is one and and he have and (the|a|i|he|his)\n",
      "> hello , my name is one and and he have it (was|,|.|had|of)\n",
      "> hello , my name is one and and he have his (had|have|was|be|man)\n",
      "> hello , my name is one and and he of (the|a|his|my|it)\n",
      "> hello , my name is one and and he of the (had|have|was|man|are)\n",
      "> hello , my name is one and and he of a (had|have|was|man|are)\n",
      "> hello , my name is one and and he of his (had|have|was|,|man)\n",
      "> hello , my name is one and and he of my (had|have|was|man|are)\n",
      "> hello , my name is one and and he of it (,|.|of|was|to)\n",
      "> hello , my name is one and and he were (the|a|,|.|his)\n",
      "> hello , my name is one and and he were the (had|have|was|man|are)\n",
      "> hello , my name is one and and he were a (had|have|was|man|are)\n",
      "> hello , my name is one and and he were , (and|i|he|it|you)\n",
      "> hello , my name is one and and he were . (i|he|the|and|it)\n",
      "> hello , my name is one and and he were his (had|have|was|man|are)\n",
      "> hello , my name is one and and it (was|,|had|.|of)\n",
      "> hello , my name is one and and it was (the|a|his|it|my)\n",
      "> hello , my name is one and and it was the (had|have|was|man|be)\n",
      "> hello , my name is one and and it was a (had|have|was|man|are)\n",
      "> hello , my name is one and and it was his (had|have|was|man|are)\n",
      "> hello , my name is one and and it was it (,|.|of|was|and)\n",
      "> hello , my name is one and and it was my (had|have|was|man|are)\n",
      "> hello , my name is one and and it , (and|i|he|it|you)\n",
      "> hello , my name is one and and it , and (the|i|he|and|a)\n",
      "> hello , my name is one and and it , i (was|had|have|were|is)\n",
      "> hello , my name is one and and it , he (was|had|have|were|of)\n",
      "> hello , my name is one and and it , it (was|had|and|,|of)\n",
      "> hello , my name is one and and it , you (was|had|have|and|were)\n",
      "> hello , my name is one and and it had (the|a|i|and|he)\n",
      "> hello , my name is one and and it had the (had|have|was|be|man)\n",
      "> hello , my name is one and and it had a (had|have|was|man|are)\n",
      "> hello , my name is one and and it had i (had|was|have|were|are)\n",
      "> hello , my name is one and and it had and (the|a|i|he|his)\n",
      "> hello , my name is one and and it had he (was|had|have|were|of)\n",
      "> hello , my name is one and and it . (i|he|and|the|it)\n",
      "> hello , my name is one and and it . i (was|had|have|were|is)\n",
      "> hello , my name is one and and it . he (was|had|have|were|is)\n",
      "> hello , my name is one and and it . and (i|he|the|and|it)\n",
      "> hello , my name is one and and it . the (had|have|was|man|are)\n",
      "> hello , my name is one and and it . it (was|had|have|and|of)\n",
      "> hello , my name is one and and it of (the|a|his|my|it)\n",
      "> hello , my name is one and and it of the (had|have|was|man|are)\n",
      "> hello , my name is one and and it of a (had|have|was|man|are)\n",
      "> hello , my name is one and and it of his (had|have|was|,|man)\n",
      "> hello , my name is one and and it of my (had|have|was|man|are)\n",
      "> hello , my name is one and and it of it (,|.|of|was|to)\n",
      "> hello , my name is one and he (was|had|have|of|,)\n",
      "> hello , my name is one and he was (the|a|his|,|.)\n",
      "> hello , my name is one and he was the (had|have|was|man|are)\n",
      "> hello , my name is one and he was the had (had|and|was|have|in)\n",
      "> hello , my name is one and he was the have (had|was|,|and|in)\n",
      "> hello , my name is one and he was the was (the|,|.|a|in)\n",
      "> hello , my name is one and he was the man (.|,|of|was|had)\n",
      "> hello , my name is one and he was the are (,|.|of|to|and)\n",
      "> hello , my name is one and he was a (had|have|was|man|are)\n",
      "> hello , my name is one and he was a had (had|have|and|was|in)\n",
      "> hello , my name is one and he was a have (had|,|was|have|and)\n",
      "> hello , my name is one and he was a was (,|.|the|a|in)\n",
      "> hello , my name is one and he was a man (.|,|of|was|had)\n",
      "> hello , my name is one and he was a are (,|.|of|in|to)\n",
      "> hello , my name is one and he was his (had|have|was|man|,)\n",
      "> hello , my name is one and he was his had (had|and|was|,|in)\n",
      "> hello , my name is one and he was his have (,|.|had|and|of)\n",
      "> hello , my name is one and he was his was (the|,|.|a|to)\n",
      "> hello , my name is one and he was his man (.|,|of|to|was)\n",
      "> hello , my name is one and he was his , (and|i|he|was|it)\n",
      "> hello , my name is one and he was , (and|i|he|it|you)\n",
      "> hello , my name is one and he was , and (the|i|he|and|a)\n",
      "> hello , my name is one and he was , i (was|had|have|were|is)\n",
      "> hello , my name is one and he was , he (was|had|have|were|of)\n",
      "> hello , my name is one and he was , it (was|had|,|and|of)\n",
      "> hello , my name is one and he was , you (was|had|have|,|of)\n",
      "> hello , my name is one and he was . (i|he|the|and|it)\n",
      "> hello , my name is one and he was . i (was|had|have|were|is)\n",
      "> hello , my name is one and he was . he (was|had|have|were|of)\n",
      "> hello , my name is one and he was . the (had|have|was|man|are)\n",
      "> hello , my name is one and he was . and (i|he|and|the|it)\n",
      "> hello , my name is one and he was . it (was|had|and|have|of)\n",
      "> hello , my name is one and he had (the|a|and|i|it)\n",
      "> hello , my name is one and he had the (had|have|was|be|man)\n",
      "> hello , my name is one and he had the had (had|and|was|have|in)\n",
      "> hello , my name is one and he had the have (had|was|and|,|in)\n",
      "> hello , my name is one and he had the was (the|a|,|.|in)\n",
      "> hello , my name is one and he had the be (,|.|of|had|was)\n",
      "> hello , my name is one and he had the man (,|.|of|was|had)\n",
      "> hello , my name is one and he had a (had|have|was|man|are)\n",
      "> hello , my name is one and he had a had (had|and|have|was|in)\n",
      "> hello , my name is one and he had a have (had|was|,|and|have)\n",
      "> hello , my name is one and he had a was (the|,|a|.|in)\n",
      "> hello , my name is one and he had a man (,|.|of|was|had)\n",
      "> hello , my name is one and he had a are (,|.|of|in|had)\n",
      "> hello , my name is one and he had and (the|a|i|he|his)\n",
      "> hello , my name is one and he had and the (had|have|was|man|be)\n",
      "> hello , my name is one and he had and a (had|have|was|man|are)\n",
      "> hello , my name is one and he had and i (was|had|have|were|of)\n",
      "> hello , my name is one and he had and he (was|had|have|of|were)\n",
      "> hello , my name is one and he had and his (had|have|was|man|are)\n",
      "> hello , my name is one and he had i (had|was|have|were|are)\n",
      "> hello , my name is one and he had i had (the|a|and|i|it)\n",
      "> hello , my name is one and he had i was (the|a|his|,|.)\n",
      "> hello , my name is one and he had i have (the|a|and|it|i)\n",
      "> hello , my name is one and he had i were (the|a|,|in|his)\n",
      "> hello , my name is one and he had i are (the|a|,|.|to)\n",
      "> hello , my name is one and he had it (was|,|had|.|of)\n",
      "> hello , my name is one and he had it was (the|a|his|it|my)\n",
      "> hello , my name is one and he had it , (and|i|he|it|you)\n",
      "> hello , my name is one and he had it had (the|a|i|and|he)\n",
      "> hello , my name is one and he had it . (i|he|and|the|it)\n",
      "> hello , my name is one and he had it of (the|a|his|my|it)\n",
      "> hello , my name is one and he have (the|a|and|his|it)\n",
      "> hello , my name is one and he have the (had|have|was|be|man)\n",
      "> hello , my name is one and he have the had (had|and|was|have|in)\n",
      "> hello , my name is one and he have the have (had|was|and|,|in)\n",
      "> hello , my name is one and he have the was (the|,|a|.|in)\n",
      "> hello , my name is one and he have the be (,|.|of|had|was)\n",
      "> hello , my name is one and he have the man (,|.|of|was|had)\n",
      "> hello , my name is one and he have a (had|have|was|man|are)\n",
      "> hello , my name is one and he have a had (had|and|have|was|in)\n",
      "> hello , my name is one and he have a have (had|was|,|have|and)\n",
      "> hello , my name is one and he have a was (the|,|a|.|in)\n",
      "> hello , my name is one and he have a man (,|.|of|was|had)\n",
      "> hello , my name is one and he have a are (,|.|of|in|had)\n",
      "> hello , my name is one and he have and (the|a|i|he|his)\n",
      "> hello , my name is one and he have and the (had|have|was|man|be)\n",
      "> hello , my name is one and he have and a (had|have|was|man|are)\n",
      "> hello , my name is one and he have and i (was|had|have|were|of)\n",
      "> hello , my name is one and he have and he (was|had|have|of|,)\n",
      "> hello , my name is one and he have and his (had|have|was|man|are)\n",
      "> hello , my name is one and he have his (had|have|was|be|man)\n",
      "> hello , my name is one and he have his had (had|and|was|have|in)\n",
      "> hello , my name is one and he have his have (,|had|.|and|was)\n",
      "> hello , my name is one and he have his was (the|,|.|a|to)\n",
      "> hello , my name is one and he have his be (.|,|of|had|to)\n",
      "> hello , my name is one and he have his man (.|,|of|was|to)\n",
      "> hello , my name is one and he have it (,|was|.|of|had)\n",
      "> hello , my name is one and he have it , (and|i|he|it|you)\n",
      "> hello , my name is one and he have it was (the|a|his|my|it)\n",
      "> hello , my name is one and he have it . (i|he|and|the|it)\n",
      "> hello , my name is one and he have it of (the|a|his|my|it)\n",
      "> hello , my name is one and he have it had (the|a|i|and|he)\n",
      "> hello , my name is one and he of (the|a|his|my|it)\n",
      "> hello , my name is one and he of the (had|have|was|man|are)\n",
      "> hello , my name is one and he of the had (had|and|was|have|in)\n",
      "> hello , my name is one and he of the have (had|was|,|and|have)\n",
      "> hello , my name is one and he of the was (the|,|.|a|in)\n",
      "> hello , my name is one and he of the man (.|,|of|was|had)\n",
      "> hello , my name is one and he of the are (,|.|of|to|and)\n",
      "> hello , my name is one and he of a (had|have|was|man|are)\n",
      "> hello , my name is one and he of a had (had|have|was|and|in)\n",
      "> hello , my name is one and he of a have (had|was|,|have|and)\n",
      "> hello , my name is one and he of a was (,|.|the|a|in)\n",
      "> hello , my name is one and he of a man (.|,|of|was|had)\n",
      "> hello , my name is one and he of a are (.|,|of|in|to)\n",
      "> hello , my name is one and he of his (had|have|was|,|man)\n",
      "> hello , my name is one and he of his had (had|and|was|,|have)\n",
      "> hello , my name is one and he of his have (,|.|had|of|and)\n",
      "> hello , my name is one and he of his was (.|,|the|a|to)\n",
      "> hello , my name is one and he of his , (and|i|he|was|it)\n",
      "> hello , my name is one and he of his man (.|,|of|to|was)\n",
      "> hello , my name is one and he of my (had|have|was|man|are)\n",
      "> hello , my name is one and he of my had (had|and|was|have|in)\n",
      "> hello , my name is one and he of my have (had|was|,|and|in)\n",
      "> hello , my name is one and he of my was (the|,|.|a|in)\n",
      "> hello , my name is one and he of my man (.|,|of|was|to)\n",
      "> hello , my name is one and he of my are (.|,|of|to|in)\n",
      "> hello , my name is one and he of it (,|.|of|was|to)\n",
      "> hello , my name is one and he of it , (and|i|he|it|you)\n",
      "> hello , my name is one and he of it . (i|he|and|the|it)\n",
      "> hello , my name is one and he of it of (the|a|his|my|it)\n",
      "> hello , my name is one and he of it was (the|a|his|,|.)\n",
      "> hello , my name is one and he of it to (the|a|his|my|it)\n",
      "> hello , my name is one and he , (and|i|he|it|you)\n",
      "> hello , my name is one and he , and (the|i|he|a|and)\n",
      "> hello , my name is one and he , and the (had|have|was|man|be)\n",
      "> hello , my name is one and he , and i (was|had|have|were|is)\n",
      "> hello , my name is one and he , and he (was|had|have|were|of)\n",
      "> hello , my name is one and he , and a (had|have|was|man|are)\n",
      "> hello , my name is one and he , and and (the|i|he|a|and)\n",
      "> hello , my name is one and he , i (was|had|have|were|is)\n",
      "> hello , my name is one and he , i was (the|a|his|it|,)\n",
      "> hello , my name is one and he , i had (the|a|and|i|it)\n",
      "> hello , my name is one and he , i have (the|a|and|i|it)\n",
      "> hello , my name is one and he , i were (the|a|,|and|in)\n",
      "> hello , my name is one and he , i is (the|a|his|,|.)\n",
      "> hello , my name is one and he , he (was|had|have|were|of)\n",
      "> hello , my name is one and he , he was (the|a|his|,|it)\n",
      "> hello , my name is one and he , he had (the|a|and|i|it)\n",
      "> hello , my name is one and he , he have (the|a|and|it|his)\n",
      "> hello , my name is one and he , he were (the|a|,|his|in)\n",
      "> hello , my name is one and he , he of (the|a|his|it|my)\n",
      "> hello , my name is one and he , it (was|had|and|,|of)\n",
      "> hello , my name is one and he , it was (the|a|his|it|my)\n",
      "> hello , my name is one and he , it had (the|a|i|and|he)\n",
      "> hello , my name is one and he , it and (the|i|a|he|it)\n",
      "> hello , my name is one and he , it , (and|i|he|it|you)\n",
      "> hello , my name is one and he , it of (the|a|his|it|my)\n",
      "> hello , my name is one and he , you (was|had|have|and|were)\n",
      "> hello , my name is one and he , you was (the|a|his|it|my)\n",
      "> hello , my name is one and he , you had (the|a|i|and|he)\n",
      "> hello , my name is one and he , you have (the|a|and|i|his)\n",
      "> hello , my name is one and he , you and (the|a|i|he|it)\n",
      "> hello , my name is one and he , you were (the|a|his|and|it)\n",
      "('Hello, my name is one and the had had the had', 1.0)\n"
     ]
    }
   ],
   "source": [
    "def gen_get_candidates(prompt:str, top:int):\n",
    "\n",
    "    words = TOKENIZER(prompt)\n",
    "    context = [vocabulary[word] for word in words]\n",
    "    context = torch.tensor(context).to(device)\n",
    "\n",
    "    output = model(context.unsqueeze(0))\n",
    "    candidates = torch.topk(output, top).indices.squeeze()\n",
    "\n",
    "    # Make confidence scores human readable\n",
    "    output_min = output.amin(dim=1)\n",
    "    output_max = output.amax(dim=1)\n",
    "    confidence = (output - output_min) / (output_max - output_min)\n",
    "\n",
    "    candidates = { vocabulary.lookup_token(x): confidence[0, x].item() for x in candidates }\n",
    "\n",
    "    print(f\"> {\" \".join(words)} ({\"|\".join(candidates.keys())})\")\n",
    "\n",
    "    return candidates\n",
    "\n",
    "gen_get_candidates(\"Once upon a time, there was\", top=5)\n",
    "\n",
    "def gen_beam_search(prompt:str, beam_width:int, beam_depth:int | None = None, branch_confidence:float = 1.0):\n",
    "\n",
    "    if beam_depth is None:\n",
    "        beam_depth = beam_width\n",
    "\n",
    "    if beam_depth < 1:\n",
    "        return prompt, branch_confidence\n",
    "\n",
    "    candidates = gen_get_candidates(prompt, beam_width)\n",
    "\n",
    "    prompt_candidates = [ gen_beam_search(prompt + ' ' + word, beam_width, beam_depth - 1, branch_confidence * confidence) for word, confidence in candidates.items() ]\n",
    "\n",
    "    return max(prompt_candidates, key=lambda x: x[1])\n",
    "    \n",
    "print(gen_beam_search(\"Hello, my name is one and\", 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
